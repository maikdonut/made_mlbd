{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hJinNSOgLsqn"
   },
   "outputs": [],
   "source": [
    "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_UA5EEuNLuVK"
   },
   "outputs": [],
   "source": [
    "#!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7G5DdbNSLuXv"
   },
   "outputs": [],
   "source": [
    "#!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0-vfhH19MWzl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DixtE4kNLuc3"
   },
   "outputs": [],
   "source": [
    "#!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0ZNDMhFUMCkf"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rDmtFco0MCqX"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Colab\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "kLZml3PSQAkV"
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('/content/drive/MyDrive/mlbd/train.csv', header=True, multiLine=True, inferSchema=True, escape='\"', sep=',', encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfs1LdX1QUIv",
    "outputId": "00d0d563-e578-4d81-a91b-af27d93f7f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|0000997932d777bf|Explanation\n",
      "Why t...|    0|           0|      0|     0|     0|            0|\n",
      "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|\n",
      "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|\n",
      "|0001b41b1c6bb37e|\"\n",
      "More\n",
      "I can't ma...|    0|           0|      0|     0|     0|            0|\n",
      "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scDLF0ze2Q53"
   },
   "source": [
    "### 1. HashingTF и IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Vb3VXUBKbG2w"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
    "words = tokenizer.transform(data)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\") \n",
    "tf = hashingTF.transform(words)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "idfModel = idf.fit(tf) \n",
    "tfidf = idfModel.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Hvr08EjecokB"
   },
   "outputs": [],
   "source": [
    "# split train/val data\n",
    "train, val = tfidf.randomSplit([0.8, 0.2], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zdjFVxfdN7r",
    "outputId": "fee12b81-7851-4e7d-fdcf-01f08a0718b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:\n",
      "(127502, 11)\n",
      "Val shape:\n",
      "(32069, 11)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print('Train shape:')\n",
    "print((train.count(), len(train.columns)))\n",
    "print('Val shape:')\n",
    "print((val.count(), len(val.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbAoMyfc154H"
   },
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "2qO8kw0Gc6dS"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol='toxic')\n",
    "lrModel = lr.fit(train)\n",
    "predictions = lrModel.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7q_lTP6jdcqD",
    "outputId": "7b538072-9b3b-4b9b-e512-928cd4b136e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9086863668360863"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='toxic')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBOv4JYvhP_c",
    "outputId": "7d0125d8-c707-4d18-84d0-f3900ab8fefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|        proba|prediction|\n",
      "+-------------+----------+\n",
      "|3.0304389E-13|       0.0|\n",
      "|          1.0|       1.0|\n",
      "|          1.0|       1.0|\n",
      "|3.8015295E-30|       0.0|\n",
      "|1.6330913E-23|       0.0|\n",
      "|3.5991588E-20|       0.0|\n",
      "|1.1098904E-27|       0.0|\n",
      "| 2.8516146E-4|       0.0|\n",
      "|2.6165605E-18|       0.0|\n",
      "| 9.940433E-12|       0.0|\n",
      "|2.0163649E-11|       0.0|\n",
      "| 6.2884395E-9|       0.0|\n",
      "|          1.0|       1.0|\n",
      "|1.4364526E-23|       0.0|\n",
      "|5.0249637E-15|       0.0|\n",
      "|          0.0|       0.0|\n",
      "|          0.0|       0.0|\n",
      "| 2.379466E-29|       0.0|\n",
      "| 1.2177003E-9|       0.0|\n",
      "| 9.9396406E-5|       0.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "extract_prob = F.udf(lambda x: float(x[1]), T.FloatType())\n",
    "(predictions.withColumn(\"proba\", extract_prob(\"probability\"))\n",
    " .select(\"proba\", \"prediction\")\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r0vRPMj2Fiv"
   },
   "source": [
    "### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "YbXoYUldhQCS"
   },
   "outputs": [],
   "source": [
    "# test data\n",
    "test = spark.read.csv('/content/drive/MyDrive/mlbd/test.csv', header=True, multiLine=True, inferSchema=True, escape='\"', sep=',', encoding = \"utf8\")\n",
    "test_tokens = tokenizer.transform(test)\n",
    "test_tf = hashingTF.transform(test_tokens)\n",
    "test_tfidf = idfModel.transform(test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBacx_SqmjSX",
    "outputId": "9a8316b6-c5e7-4ae3-95ed-5884a6c0c13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with label:  toxic\n",
      "Prediction added\n",
      "Start with label:  severe_toxic\n",
      "Prediction added\n",
      "Start with label:  obscene\n",
      "Prediction added\n",
      "Start with label:  threat\n",
      "Prediction added\n",
      "Start with label:  insult\n",
      "Prediction added\n",
      "Start with label:  identity_hate\n",
      "Prediction added\n",
      "+----------------+------------+------------+-------------+-------------+-------------+-------------+\n",
      "|              id|       toxic|severe_toxic|      obscene|       threat|       insult|identity_hate|\n",
      "+----------------+------------+------------+-------------+-------------+-------------+-------------+\n",
      "|000968ce11f5ee34|1.8862696E-9|5.568692E-10| 0.0026673032|1.8312777E-11| 6.9151815E-7|1.5654224E-11|\n",
      "|00491682330fdd1d|         0.0|         0.0|          0.0|          0.0|          0.0|          0.0|\n",
      "|008eb47c4684d190|         1.0|         0.0|          0.0|          0.0|          0.0|          0.0|\n",
      "|00d251f47486b6d2|1.5149961E-8| 1.391695E-9|1.9929523E-11|2.7775447E-12|  2.732317E-4| 1.5385221E-7|\n",
      "|0114ae82c53101a9|   0.9999999| 0.018135732|        0.987| 1.582535E-22|1.9036806E-16| 4.9053153E-7|\n",
      "+----------------+------------+------------+-------------+-------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "for label in labels:\n",
    "    print('Start with label: ',label)\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=label)\n",
    "    lrModel = lr.fit(tfidf)\n",
    "    res = lrModel.transform(test_tfidf)\n",
    "    test_res = test_res.join(res.select('id', 'probability'), on=\"id\")\n",
    "    test_res = test_res.withColumn(label, extract_prob('probability')).drop(\"probability\")\n",
    "    print('Prediction added')\n",
    "test_res.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdHBnfHS2X8I"
   },
   "source": [
    "### 2. Word2Vec   \n",
    "не сделано"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
